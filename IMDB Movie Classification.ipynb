{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vaderSentiment in c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv( r\"C:\\Users\\cdumitrascu\\OneDrive - ENDAVA\\Desktop\\ML\\test.csv\",dtype='object')\n",
    "train_data = pd.read_csv( r\"C:\\Users\\cdumitrascu\\OneDrive - ENDAVA\\Desktop\\ML\\train.csv\",dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv(\"../input/movie-reviews-classification/train.csv\")\n",
    "#test_data = pd.read_csv(\"../input/movie-reviews-classification/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_id</th>\n",
       "      <th>primary_title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>genres</th>\n",
       "      <th>start_year</th>\n",
       "      <th>end_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>text</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0400837</td>\n",
       "      <td>Snuff killer - La morte in diretta</td>\n",
       "      <td>Snuff killer - La morte in diretta</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "      <td>2003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>A cheap exploitation film about a mothers sear...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0036038</td>\n",
       "      <td>In Old Oklahoma</td>\n",
       "      <td>In Old Oklahoma</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Romance,Western</td>\n",
       "      <td>1943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.0</td>\n",
       "      <td>John Wayne &amp; Albert Dekker compete for oil rig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0493430</td>\n",
       "      <td>Jackass Number Two</td>\n",
       "      <td>Jackass Number Two</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action,Comedy,Documentary</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.0</td>\n",
       "      <td>This film tops the previous incarnation by a m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0089603</td>\n",
       "      <td>Mishima: A Life in Four Chapters</td>\n",
       "      <td>Mishima: A Life in Four Chapters</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Biography,Drama</td>\n",
       "      <td>1985</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>The only pure life, is one that ends with a si...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0427038</td>\n",
       "      <td>Carlito's Way: Rise to Power</td>\n",
       "      <td>Carlito's Way: Rise to Power</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "      <td>2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>really awful... lead actor did OK... the film,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id   title_id                       primary_title  \\\n",
       "0  0  tt0400837  Snuff killer - La morte in diretta   \n",
       "1  1  tt0036038                     In Old Oklahoma   \n",
       "2  2  tt0493430                  Jackass Number Two   \n",
       "3  3  tt0089603    Mishima: A Life in Four Chapters   \n",
       "4  4  tt0427038        Carlito's Way: Rise to Power   \n",
       "\n",
       "                       original_title is_adult                     genres  \\\n",
       "0  Snuff killer - La morte in diretta      0.0            Horror,Thriller   \n",
       "1                     In Old Oklahoma      0.0            Romance,Western   \n",
       "2                  Jackass Number Two      0.0  Action,Comedy,Documentary   \n",
       "3    Mishima: A Life in Four Chapters      0.0            Biography,Drama   \n",
       "4        Carlito's Way: Rise to Power      0.0         Action,Crime,Drama   \n",
       "\n",
       "  start_year end_year runtime_minutes  \\\n",
       "0       2003      NaN            88.0   \n",
       "1       1943      NaN           102.0   \n",
       "2       2006      NaN            92.0   \n",
       "3       1985      NaN           120.0   \n",
       "4       2005      NaN           100.0   \n",
       "\n",
       "                                                text polarity  \n",
       "0  A cheap exploitation film about a mothers sear...        0  \n",
       "1  John Wayne & Albert Dekker compete for oil rig...        0  \n",
       "2  This film tops the previous incarnation by a m...        1  \n",
       "3  The only pure life, is one that ends with a si...        1  \n",
       "4  really awful... lead actor did OK... the film,...        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[['text','start_year','is_adult','genres']]\n",
    "test = test_data[['text','start_year','is_adult','genres']]\n",
    "train_labels=train_data['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start_year</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A cheap exploitation film about a mothers sear...</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Wayne &amp; Albert Dekker compete for oil rig...</td>\n",
       "      <td>1943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Romance,Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This film tops the previous incarnation by a m...</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action,Comedy,Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The only pure life, is one that ends with a si...</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Biography,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really awful... lead actor did OK... the film,...</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text start_year is_adult  \\\n",
       "0  A cheap exploitation film about a mothers sear...       2003      0.0   \n",
       "1  John Wayne & Albert Dekker compete for oil rig...       1943      0.0   \n",
       "2  This film tops the previous incarnation by a m...       2006      0.0   \n",
       "3  The only pure life, is one that ends with a si...       1985      0.0   \n",
       "4  really awful... lead actor did OK... the film,...       2005      0.0   \n",
       "\n",
       "                      genres  \n",
       "0            Horror,Thriller  \n",
       "1            Romance,Western  \n",
       "2  Action,Comedy,Documentary  \n",
       "3            Biography,Drama  \n",
       "4         Action,Crime,Drama  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>start_year</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>those people,who told me\"this movie is good\"-s...</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action,Crime,Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nick Millard aka Nick Phillips should have lef...</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Horror,Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I saw this movie at age 6, it was in the ...</td>\n",
       "      <td>1985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action,Adventure,Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not having heard of this film, it came as a su...</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Falsely accused, skirt-chasing chums John Wayn...</td>\n",
       "      <td>1935</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action,Adventure,Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text start_year is_adult  \\\n",
       "0  those people,who told me\"this movie is good\"-s...       2005      0.0   \n",
       "1  Nick Millard aka Nick Phillips should have lef...       1987      0.0   \n",
       "2  When I saw this movie at age 6, it was in the ...       1985      0.0   \n",
       "3  Not having heard of this film, it came as a su...       2003      0.0   \n",
       "4  Falsely accused, skirt-chasing chums John Wayn...       1935      0.0   \n",
       "\n",
       "                       genres  \n",
       "0          Action,Crime,Drama  \n",
       "1             Horror,Thriller  \n",
       "2  Action,Adventure,Animation  \n",
       "3                    Thriller  \n",
       "4    Action,Adventure,Romance  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "def filter(train):\n",
    "    train['modi']=train['text'].str.lower()\n",
    "    i=0\n",
    "    for x in train['modi']:\n",
    "        for y in x:\n",
    "            if y in punctuation:\n",
    "                train['modi'][i]=train['modi'][i].replace(y,'')\n",
    "        train['modi'][i]=train['modi'][i].replace('br','')\n",
    "        i+=1\n",
    "    train = pd.concat([train.drop(['modi'], axis=1), train['modi'].apply(pd.Series)], axis=1)\n",
    "filter(train)\n",
    "filter(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A cheap exploitation film about a mothers search for her daughter who has been kidnapped by people who make snuff porno films. The trail leads the mother all over Europe as she searches for her child and we in the audience struggle to stay asleep.<br /><br />This is one of the countless soft-core sleaze films that are made for people who want the excitement of porno with out the stigma or danger of it showing up on their credit card bill.Personally I'd rather have the stigma since those films tend to be more interesting and honest about what we're seeing. This is suppose to be a sexy thriller but its not. Mostly its people talking about things followed by lots of walking from place to place and lead to lead.Periodically through out the film various people get undressed and everything has more than a touch of S&M to the proceedings. The violence and fetish material is of the sort to provoke laughter rather than horror or even excitement, its all so incredibly fake. Worse there is not even enough nudity to keep it interesting. (Basically par for the course for many of these films)<br /><br />You'll forgive my lack of details but it simply is a dull boring film that I stayed with to the end hoping for something remotely prurient to occur, but there was nothing. The most interesting thing was the blonde haired villainess with the huge over bite and nose the size of a Buick. I watched her with morbid fascination wondering what she had looked like as a young girl and wondering whether she had had plastic surgery, not the type of things you should be thinking about in a gripping thriller.<br /><br />Avoid.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a cheap exploitation film about a mothers search for her daughter who has been kidnapped by people who make snuff porno films the trail leads the mother all over europe as she searches for her child and we in the audience struggle to stay asleep  this is one of the countless softcore sleaze films that are made for people who want the excitement of porno with out the stigma or danger of it showing up on their credit card billpersonally id rather have the stigma since those films tend to be more interesting and honest about what were seeing this is suppose to be a sexy thriller but its not mostly its people talking about things followed by lots of walking from place to place and lead to leadperiodically through out the film various people get undressed and everything has more than a touch of sm to the proceedings the violence and fetish material is of the sort to provoke laughter rather than horror or even excitement its all so incredibly fake worse there is not even enough nudity to keep it interesting basically par for the course for many of these films  youll forgive my lack of details but it simply is a dull boring film that i stayed with to the end hoping for something remotely prurient to occur but there was nothing the most interesting thing was the blonde haired villainess with the huge over bite and nose the size of a buick i watched her with morbid fascination wondering what she had looked like as a young girl and wondering whether she had had plastic surgery not the type of things you should be thinking about in a gripping thriller  avoid'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['modi'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train['modi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "def filter_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    stems = []\n",
    "    for t in tokens:    \n",
    "        stems.append(porter.stem(t))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train['modi']= train['modi'].apply(lambda x : filter_text(x))\n",
    "test['modi']= test['modi'].apply(lambda x : filter_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cheap', 'exploit', 'film', 'mother', 'search', 'daughter', 'kidnap', 'peopl', 'make', 'snuff', 'porno', 'film', 'trail', 'lead', 'mother', 'europ', 'search', 'child', 'audienc', 'struggl', 'stay', 'asleep', 'one', 'countless', 'softcor', 'sleaz', 'film', 'made', 'peopl', 'want', 'excit', 'porno', 'stigma', 'danger', 'show', 'credit', 'card', 'billperson', 'id', 'rather', 'stigma', 'sinc', 'film', 'tend', 'interest', 'honest', 'see', 'suppos', 'sexi', 'thriller', 'mostli', 'peopl', 'talk', 'thing', 'follow', 'lot', 'walk', 'place', 'place', 'lead', 'leadperiod', 'film', 'variou', 'peopl', 'get', 'undress', 'everyth', 'touch', 'sm', 'proceed', 'violenc', 'fetish', 'materi', 'sort', 'provok', 'laughter', 'rather', 'horror', 'even', 'excit', 'incred', 'fake', 'wors', 'even', 'enough', 'nuditi', 'keep', 'interest', 'basic', 'par', 'cours', 'mani', 'film', 'youll', 'forgiv', 'lack', 'detail', 'simpli', 'dull', 'bore', 'film', 'stay', 'end', 'hope', 'someth', 'remot', 'prurient', 'occur', 'noth', 'interest', 'thing', 'blond', 'hair', 'villai', 'huge', 'bite', 'nose', 'size', 'buick', 'watch', 'morbid', 'fascin', 'wonder', 'look', 'like', 'young', 'girl', 'wonder', 'whether', 'plastic', 'surgeri', 'type', 'thing', 'think', 'grip', 'thriller', 'avoid']\n"
     ]
    }
   ],
   "source": [
    "print(train['modi'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "train['modi']=train['modi'].apply(lambda x: TreebankWordDetokenizer().detokenize(x))\n",
    "test['modi']=test['modi'].apply(lambda x: TreebankWordDetokenizer().detokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text          Nick Millard aka Nick Phillips should have lef...\n",
      "start_year                                                 1987\n",
      "is_adult                                                    0.0\n",
      "genres                                          Horror,Thriller\n",
      "modi          nick millard aka nick phillip left wellenough ...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test.loc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "def vader(train):\n",
    "    analyser = SentimentIntensityAnalyzer()\n",
    "    train['vader']=train['text'].apply(lambda x : analyser.polarity_scores(x))\n",
    "    train = pd.concat([train.drop(['vader'], axis=1), train['vader'].apply(pd.Series)], axis=1)\n",
    "    train['lenght'] = train['text'].apply(lambda x : len(x))\n",
    "    train['words'] = train['text'].apply(lambda x :len(x.split(\" \")))\n",
    "    train['blob']=train['text'].apply(lambda x : TextBlob(x).sentiment)\n",
    "    train = pd.concat([train.drop(['blob'], axis=1), train['blob'].apply(pd.Series)], axis=1)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(train):\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train[\"modi\"].apply(lambda x: x.split(\" \")))]\n",
    "    model = Doc2Vec(documents, workers=1,vector_size=4,window=1,min_count = 1,seed=10)\n",
    "    doc2vec_df = train[\"modi\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "    doc2vec_df.columns = [\"d2v_\" + str(x) for x in doc2vec_df.columns]\n",
    "    train = pd.concat([train, doc2vec_df], axis=1)\n",
    "    \n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train[\"genres\"].apply(lambda x: x.split(\" \")))]\n",
    "    # train a Doc2Vec model with our text data\n",
    "    model = Doc2Vec(documents, workers=1,window=1,vector_size=4,min_count = 1,seed=10)\n",
    "\n",
    "    # transform each document into a vector data\n",
    "    doc2vec_df = train[\"genres\"].apply(lambda x: model.infer_vector(x.split(\" \"))).apply(pd.Series)\n",
    "    doc2vec_df.columns = [\"group_\" + str(x) for x in doc2vec_df.columns]\n",
    "    train = pd.concat([train, doc2vec_df], axis=1)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "def making_features(train,test):\n",
    "    train = vader(train)\n",
    "    test = vader(test)\n",
    "    train = doc2vec(train)\n",
    "    test = doc2vec(test)\n",
    "    \n",
    "    \n",
    "    tfidf = TfidfVectorizer(min_df=100)\n",
    "    \n",
    "    \n",
    "    tfidf.fit(train[\"modi\"])\n",
    "    tfidf.fit(test['modi'])\n",
    "    \n",
    "    tfidf_result = tfidf.transform(train[\"modi\"]).toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "    tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "    tfidf_df.index = train.index\n",
    "    train = pd.concat([train, tfidf_df], axis=1)\n",
    "    \n",
    "    \n",
    "    tfidf_result = tfidf.transform(test[\"modi\"]).toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "    tfidf_df.columns = [\"word_\" + str(x) for x in tfidf_df.columns]\n",
    "    tfidf_df.index = test.index\n",
    "    test = pd.concat([test, tfidf_df], axis=1)\n",
    "    \n",
    "    \n",
    "    train['start_year']=train['start_year'].astype('int')\n",
    "    train['is_adult']=train['is_adult'].astype('bool')\n",
    "    test['start_year']=test['start_year'].astype('int')\n",
    "    test['is_adult']=test['is_adult'].astype('bool')\n",
    "    train.fillna(0,inplace=True)\n",
    "    return (train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "x,y = making_features(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for o in x.columns:\n",
    "    #print(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27000, 3290)\n",
      "(20000, 3290)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(x.shape)\n",
    "from sklearn.model_selection import train_test_split\n",
    "ignore_cols = ['text','modi','genres']\n",
    "features = [c for c in y.columns if c not in ignore_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x[features], train_labels, test_size=0.33,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13400, 3287)\n"
     ]
    }
   ],
   "source": [
    "ignore_cols = ['text','modi','genres',]\n",
    "features = [c for c in x.columns if c not in ignore_cols]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1028 11:56:58.141414 19724 deprecation_wrapper.py:119] From c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1028 11:56:58.154382 19724 deprecation_wrapper.py:119] From c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1028 11:56:58.156416 19724 deprecation_wrapper.py:119] From c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense,Activation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "import keras\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(26, input_shape=(x.shape[1]-3,)),\n",
    "    Activation('relu'),\n",
    "    Dense(11),\n",
    "    Activation('relu'),\n",
    "    Dense(6),\n",
    "    Activation('relu'),\n",
    "    Dense(1),\n",
    "    Activation('sigmoid'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 26)                85488     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                297       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 7         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 85,864\n",
      "Trainable params: 85,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 11:56:58.247136 19724 deprecation_wrapper.py:119] From c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1028 11:56:58.252120 19724 deprecation_wrapper.py:119] From c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1028 11:56:58.258105 19724 deprecation.py:323] From c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "model.compile(optimizers.adam(lr=0.001),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 11:57:01.318235 19724 deprecation_wrapper.py:119] From c:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 6600 samples\n",
      "Epoch 1/100\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.7351 - acc: 0.5007 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 2/100\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 3/100\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 4/100\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 5/100\n",
      "20000/20000 [==============================] - 34s 2ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 6/100\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.6932 - acc: 0.4993 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 7/100\n",
      "20000/20000 [==============================] - 33s 2ms/step - loss: 0.6932 - acc: 0.5020 - val_loss: 0.6931 - val_acc: 0.5035\n",
      "Epoch 8/100\n",
      "16700/20000 [========================>.....] - ETA: 4s - loss: 0.6932 - acc: 0.5006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-79726dc85c6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\cdumitrascu\\.conda\\envs\\pythoncompvision\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    190\u001b[0m                                     \u001b[1;34m'If using HDF5 input data, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                                     'pass shuffle=\"batch\".')\n\u001b[1;32m--> 192\u001b[1;33m                 \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x[features],train_labels,epochs=100,validation_data=(X_test,y_test), batch_size=100,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = ['text','modi','genres','group']\n",
    "features = [c for c in y.columns if c not in ignore_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(X_test,y_test))\n",
    "print(model.evaluate(x[features],train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(X_test,y_test))\n",
    "print(model.evaluate(x[features],train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(y[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(r\"C:\\Users\\cdumitrascu\\OneDrive - ENDAVA\\Desktop\\ML\\sampleSubmission.csv\")\n",
    "#submission = pd.read_csv('../input/movie-reviews-classification/sampleSubmission.csv')\n",
    "submission['polarity'] = y_pred\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
